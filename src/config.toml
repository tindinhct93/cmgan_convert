[main]
name = "CMGAN_valentini_sample_weight"
seed = 42
epochs = 127
cut_len = 32000
save_model_dir = "./save_model"
use_amp = true # whether to use Automatic precision to speed up 
# device_ids = "0,1,2"
sr = 16000
interval_eval = 5
resume = true
max_clip_grad_norm = 2.0 # torch.nn.utils.max_clip_grad_norm
gradient_accumulation_steps = 1
num_prints = 5

# augmentation method
[main.augment]
remix = true

# You can experiment on different weights for final loss combination
[main.loss_weights]
ri = 0.1
mag = 0.9
time = 0.2  
gan =  0.05


# Config model
[model]
num_channel = 64

# Config feature
[feature]
n_fft = 400
hop = 100
ndf = 16


[dataset_train]
path = "/data1/speech/khanhnnm/database/denoiser_db/valentini_2017/train"
[dataset_train.dataloader]
batchsize = 4
n_worker = 4
pin_memory = true

[dataset_train.sampler]
shuffle = true 
drop_last = true
    
[dataset_valid]
path = "/data1/speech/khanhnnm/database/denoiser_db/valentini_2017/test"
    
[dataset_valid.dataloader]
batchsize = 4
n_worker = 4

[dataset_valid.sampler]
shuffle = false
drop_last = false 

[dataset_test]
path = "/data1/speech/khanhnnm/database/denoiser_db/valentini_2017/test"


[optimizer]
init_lr = 5e-4

[scheduler]
decay_epoch = 30
gamma = 0.5

[trainer]
path = "trainer.trainer.Trainer"


    
    

